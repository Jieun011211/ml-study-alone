{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 랜덤 포레스트\n",
    "앙상블 학습의 대표주자\n",
    "- 결정 트리를 랜덤하게 만들어 숲을 만든다. 그리고 각 결정 트리의 예측을 사용해 최종 예측을 만든다.\n",
    "- 부트스트랩 샘플: 훈련 데이터에서 랜덤하게 샘플을 추출하여 생성, 중복 가능성이 있고 훈련 세트와 크기가 같다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "wine = pd.read_csv('https://bit.ly/wine_csv_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n",
    "target = wine['class'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_input, test_input, train_target, test_target = train_test_split(data, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과 값: 훈련세트에 과대적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9973541965122431 0.8905151032797809\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특성 중요도 확인해보기\n",
    "- 랜덤 포레스트가 특성의 일부를 랜덤하게 선택하여 결과값 변경됨(234p 비교)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23167441 0.50039841 0.26792718]\n"
     ]
    }
   ],
   "source": [
    "rf.fit(train_input, train_target)\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOB 샘플\n",
    "out of bag: 부트스트랩 샘플에 포함되지 않고 남는 샘플\n",
    "- 검증 세트 역할             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8934000384837406\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n",
    "rf.fit(train_input, train_target)\n",
    "print(rf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 엑스트라 트리\n",
    "부트스트랩 샘플을 사용하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "교차 검증 점수 확인해보기\n",
    "- 결과 값: 랜덤 포레스트와 비슷한 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9974503966084433 0.8887848893166506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n",
    "scores = cross_validate(et, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특성 중요도 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20183568 0.52242907 0.27573525]\n"
     ]
    }
   ],
   "source": [
    "et.fit(train_input, train_target)\n",
    "print(et.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그레이디언트 부스팅\n",
    "깊이가 얕은 결정 트리를 사용하여 이전 트리의 오차를 보완하는 방식으로 앙상블\n",
    "- 경사 하강법 사용\n",
    "- 과대적합에 강하다\n",
    "- 성능이 좋지만 순서대로 트리를 추가하기 때문에 훈련 속도가 느리다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8881086892152563 0.8720430147331015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "scores = cross_validate(gb, train_input, train_target,\n",
    "                        return_train_score=True, n_jobs=-1) # return_train_score=True : 훈련 세트의 점수도 함께 반환\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9464595437171814 0.8780082549788999\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2,random_state=42)\n",
    "scores = cross_validate(gb, train_input, train_target,\n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤 포레스트보다 일부 특성(당도)에 집중한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15887763 0.6799705  0.16115187]\n"
     ]
    }
   ],
   "source": [
    "gb.fit(train_input, train_target)\n",
    "print(gb.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 히스토그램 기반 그레이디언트 부스팅\n",
    "입력 특성을 256개의 구간으로 나눠서 하나를 떼어 놓고, 누락된 값을 위해 사용한다.\n",
    "- 입력에 누락된 특성이 있어도 따로 전처리할 필요가 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leejieun/miniforge3/envs/ai/lib/python3.12/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:15: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9321723946453317 0.8801241948619236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "hgb = HistGradientBoostingClassifier(random_state=42)\n",
    "scores = cross_validate(hgb, train_input, train_target, return_train_score=True)\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특성 중요도 결과 값: [특성 중요도, 평균, 표준편차]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08876275 0.23438522 0.08027708]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "hgb.fit(train_input, train_target)\n",
    "result = permutation_importance(hgb, train_input, train_target,\n",
    "                                n_repeats=10, random_state=42, n_jobs=-1)\n",
    "print(result.importances_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 세트에서 특성 중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05969231 0.20238462 0.049     ]\n"
     ]
    }
   ],
   "source": [
    "result = permutation_importance(hgb, test_input, test_target, n_repeats=10, random_state=42, n_jobs=-1) # n_repeats=10 : 랜덤하게 섞을 횟수\n",
    "print(result.importances_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8723076923076923"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgb.score(test_input, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost 라이브러리를 사용하여 교차 검증 점수 구해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Channels:\n",
      " - conda-forge\n",
      " - nvidia\n",
      " - pytorch\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 23.11.0\n",
      "    latest version: 24.3.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/leejieun/miniforge3/envs/ai\n",
      "\n",
      "  added / updated specs:\n",
      "    - xgboost\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _py-xgboost-mutex-2.0      |            gpu_0          12 KB  conda-forge\n",
      "    cuda-version-12.4          |       h3060b56_3          21 KB  conda-forge\n",
      "    libxgboost-2.0.3           |cuda120_h75debf4_1       163.5 MB  conda-forge\n",
      "    nccl-2.20.5.1              |       h3a97aeb_0       104.0 MB  conda-forge\n",
      "    py-xgboost-2.0.3           |cuda118_pyhedeaf28_1         129 KB  conda-forge\n",
      "    xgboost-2.0.3              |cuda118_pyh5ebfdf7_1          16 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       267.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _py-xgboost-mutex  conda-forge/linux-64::_py-xgboost-mutex-2.0-gpu_0 \n",
      "  cuda-version       conda-forge/noarch::cuda-version-12.4-h3060b56_3 \n",
      "  libxgboost         conda-forge/linux-64::libxgboost-2.0.3-cuda120_h75debf4_1 \n",
      "  nccl               conda-forge/linux-64::nccl-2.20.5.1-h3a97aeb_0 \n",
      "  py-xgboost         conda-forge/noarch::py-xgboost-2.0.3-cuda118_pyhedeaf28_1 \n",
      "  xgboost            conda-forge/noarch::xgboost-2.0.3-cuda118_pyh5ebfdf7_1 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "libxgboost-2.0.3     | 163.5 MB  |                                       |   0% \n",
      "nccl-2.20.5.1        | 104.0 MB  |                                       |   0% \u001b[A\n",
      "\n",
      "py-xgboost-2.0.3     | 129 KB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "cuda-version-12.4    | 21 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "xgboost-2.0.3        | 16 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-2.0.3     | 163.5 MB  | #                                     |   3% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "cuda-version-12.4    | 21 KB     | ############################8         |  78% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libxgboost-2.0.3     | 163.5 MB  | #2                                    |   3% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "cuda-version-12.4    | 21 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "libxgboost-2.0.3     | 163.5 MB  | #7                                    |   5% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_py-xgboost-mutex-2. | 12 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_py-xgboost-mutex-2. | 12 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libxgboost-2.0.3     | 163.5 MB  | ##                                    |   5% \u001b[A\u001b[A\n",
      "\n",
      "libxgboost-2.0.3     | 163.5 MB  | ###                                   |   8% \u001b[A\u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ###5                                  |  10% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ####3                                 |  12% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ####6                                 |  12% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ####9                                 |  13% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "xgboost-2.0.3        | 16 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libxgboost-2.0.3     | 163.5 MB  | #####1                                |  14% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | #####6                                |  15% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | #####9                                |  16% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ######4                               |  18% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ######9                               |  19% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | #######2                              |  19% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | #######4                              |  20% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ########1                             |  22% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ########4                             |  23% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ########7                             |  24% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ########9                             |  24% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | #########                             |  24% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | #########5                            |  26% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ##########                            |  27% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ##########7                           |  29% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ###########                           |  30% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ###########9                          |  32% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ############3                         |  33% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ############9                         |  35% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | #############1                        |  36% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | #############6                        |  37% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ##############2                       |  38% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ##############3                       |  39% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ##############5                       |  39% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ###############7                      |  43% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ################2                     |  44% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ################7                     |  45% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ########2                             |  22% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ################9                     |  46% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | #################1                    |  46% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | #################2                    |  47% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | #################5                    |  48% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ##################3                   |  50% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ##################5                   |  50% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ###################1                  |  52% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ###################4                  |  53% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ###################6                  |  53% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ###################9                  |  54% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ####################8                 |  56% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | #####################2                |  57% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | #####################9                |  59% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ######################9               |  62% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | #######################1              |  63% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | #######################9              |  65% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ########################1             |  65% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ########################2             |  66% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ########################4             |  66% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ########################8             |  67% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | #########################1            |  68% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | #########################6            |  69% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | #########################9            |  70% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ##########################5           |  72% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ###########################4          |  74% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ###########################8          |  75% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ############################          |  76% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ############################5         |  77% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ############################7         |  78% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ############################8         |  78% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | #############################1        |  79% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | #############################9        |  81% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ##############################3       |  82% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ##############################5       |  83% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ################################1     |  87% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ################################5     |  88% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | #################################7    |  91% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ##################################1   |  92% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ##################################9   |  94% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ###################################4  |  96% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ###################################6  |  96% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ####################################  |  98% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ####################################5 |  99% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ####################################7 |  99% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ####################################8 | 100% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | #######################6              |  64% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | #######################8              |  65% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ########################1             |  65% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ########################3             |  66% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ########################5             |  66% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ########################7             |  67% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ########################9             |  67% \u001b[A\n",
      "libxgboost-2.0.3     | 163.5 MB  | ##################################### | 100% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | #########################3            |  68% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | #########################5            |  69% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | #########################7            |  70% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ##########################            |  70% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ##########################2           |  71% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ##########################5           |  72% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ##########################8           |  73% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ###########################1          |  73% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ###########################4          |  74% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ###########################8          |  75% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ############################2         |  76% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ############################6         |  77% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ############################9         |  78% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | #############################4        |  79% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | #############################9        |  81% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ##############################2       |  82% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ##############################6       |  83% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ###############################       |  84% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ###############################4      |  85% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ###############################8      |  86% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ################################2     |  87% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ################################6     |  88% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ################################9     |  89% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | #################################4    |  90% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | #################################8    |  91% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ##################################2   |  93% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ##################################6   |  94% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ###################################   |  95% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ###################################4  |  96% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ###################################8  |  97% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ####################################2 |  98% \u001b[A\n",
      "nccl-2.20.5.1        | 104.0 MB  | ####################################6 |  99% \u001b[A\n",
      "                                                                                \u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#conda install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9558403027491312 0.8782000074035686\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(tree_method='hist', random_state=42)\n",
    "scores = cross_validate(xgb, train_input, train_target, return_train_score=True)\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

## python 함수 및 용어 정리
- zip() : 나열된 리스트에서 원소를 하나씩 꺼내주는 함수
- predict() : 새로운 데이터의 정답을 예측하는 함수
- fit() : 모델을 훈련하는 함수
- score() : 모델을 평가하는 함수
- scatter() : 산점도를 그리는 맷플롯립 함수
- KNeighborsClassifier() : k-최근접 이웃 분류 모델을 만드는 사이킷런 클래스
    - n_neighbors 매개변수로 이웃의 갯수를 지정한다.
    - 기본 값: 5
- 인덱스 슬라이싱: 콜론(:)을 사이에 두고 범위를 지정하여 출력
    - 마지막 인덱스의 원소는 미포함
    - [:5] : 처음부터 시작하는 인덱스의 경우 0 생략 가능
    - [44:] : 44부터 마지막 인덱스까지 출력
- reshape(): 넘파이 배열의 크기를 바꾼다.
- mean_absolute_error():타깃과 예측의 절댓값 오차를 평균하여 반환하는 함수(sklearn.metrics 패키지)
- arange(): 시작, 끝 값을 지정하여 배열 생성하는 함수
- kneighbors(): k-최근접 이웃 모델의 가장 가까운 이웃까지의 거리와 이웃 샘플의 인덱스를 얻을 수 있는 함수
- column_stack(): 전달받은 리스트를 일렬로 세운 후 차례대로 나란히 연결
- 브로드캐스팅: numpy 배열 사이에서 일어난다. 모든 행에 적용시켜주는 것
- 사이킷런의 변환기: 특성을 만들거나 전처리하는 클래스, 타깃 데이터가 필요하지 않다.
    - PolynomialFeatures class
    - fit(): 새롭게 만들 특성 조합
    - transform(): 실제로 데이터를 변환
- get_feature_names_out(): 각 특성의 조합에 대해 나열
- 하이퍼파라미터: 사람이 알려줘야하는 파라미터(릿지의 alpha 등)
- head(): 처음 5개 행을 출력하는 함수
- unique(): 고유한 값을 추출하는 함수
- predict_proba(): 클래스별 확률 값을 알려주는 함수
- round(): 기본 소수점 첫째 자리에서 반올림하는 함수(decimals= 유지할 소수점 아래 자릿 수)
- exp(): 지수 계산하는 함수
- decision_function(): 로지스틱 회귀 모델이 학습한 방정식의 값 z
- expit(): 시그모이드 함수
- info(): dataframe 의 각 열의 데이터 타입, 누락된 데이터를 확인하는 함수
- describe(): 열에 대한 간략한 통계를 출력하는 함수
- cross_validate(): 교차 검증 함수(기본: 5-폴드 교차 검증)
- argmax(): 가장 큰 값의 인덱스 추출하는 함수
- permutation_importance(): 히스토그램 기반 그레이디언트 부스팅의 특성 중요도를 계산하는 함수
- argsort(): 오름차순으로 나열하는 함수
- mean(): 평균값 계산하는 함수
- ratio 매개변수: figsize 지정, 기본값=1
- inverse_transform(): transform() 메서드로 차원을 축소시킨 데이터를 복원
- load_data(): keras fashion mnist 모듈 아래에서 사용하는 훈련, 테스트 데이터 분할하는 함수
- evaluate(): 모델의 성능을 평가하는 함수
- summary(): 층에 대한 유용한 정보
- SGD: 기본 경사 하강법 옵티마이저 클래스
    - learning_rate 매개변수: 학습률 지정 / 기본값 0.01
    - momentum 매개변수: 0 이상 값 지정 -> 모멘텀 최적화를 수행
    - nesterov 매개변수: True -> 네스테로프 모멘텀 최적화
- Adagrad: Adargrad 옵티마이저 클래스
    - learning_rate 매개변수: 학습률 지정 / 기본값 0.001
    - 그레이디언트 제곱을 누적하여 학습률을 나눈다.
        - initial_accumulator_value 매개변수: 누적 초깃값 지정 / 기본값 0.1
- RMSprop: RMSprop 옵티마이저 클래스
    - learning_rate 매개변수: 학습률 지정 / 기본값 0.001
    - Adagrad 처럼 학습률을 나누지만 최근의 그레이디언트를 사용하기 위해 지수 감소를 사용
        - rho 매개변수: 감소 비율을 지정 / 기본값 0.9
- Adam: Adam 옵티마이저 클래스
    - learning_rate 매개변수: 학습률 지정 / 기본값 0.001
    - beta_1 매개변수: 모멘텀 최적화에 있는 그레이디언트의 지수 감소 평균 조절
    - beta_2 매개변수: RMSprop 에 있는 그레이디언트 제곱의 지수 감소 평균 조절
- save_weights(): 훈련된 모델의 파라미터를 저장하는 메서드
- save(): 모델 구조와 파라미터를 함께 저장하는 메서드
- pad_sequences(): 시퀀스 길이를 맞추기 위해 패딩을 추가
  - maxlen 매개변수: 원하는 시퀀스 길이 지정
  - padding 매개변수: 패딩 추가 위치, 기본값 pre_ 시퀀스 앞 / post_ 시퀀스 뒤
  - truncating 매개변수: 자를 위치, 기본값 pre_ 시퀀스 앞 / post_ 시퀀스 뒤